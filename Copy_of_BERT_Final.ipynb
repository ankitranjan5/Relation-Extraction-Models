{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MF7s6yuVfBV",
        "outputId": "d16d6601-bd50-4c16-a5a1-b781543b2365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UnFAq4NmxQyn",
        "outputId": "3b36be20-b395-4ac9-c899-2b426daac505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2dgHw56VwRE"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # This will prompt for authorization.\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wVpj24cVwTl",
        "outputId": "27e677de-9c9b-496c-87ef-11758f90da3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recordclass\n",
            "  Downloading recordclass-0.17.2.tar.gz (446 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 446 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: recordclass\n",
            "  Building wheel for recordclass (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for recordclass: filename=recordclass-0.17.2-cp37-cp37m-linux_x86_64.whl size=288787 sha256=f574ba410b6e8fb8302cd54561465eaf671072688e2f49388dcc12f71f4cfc4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/a7/f2/f1b5af34322f1cc71e5a877d03056a188728509fcadf683197\n",
            "Successfully built recordclass\n",
            "Installing collected packages: recordclass\n",
            "Successfully installed recordclass-0.17.2\n"
          ]
        }
      ],
      "source": [
        "!pip install recordclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cogPkjBPVwWZ",
        "outputId": "32fee112-331b-49aa-fa90-bb18b8add458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.21.26-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 43.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 21.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.10.0.2)\n",
            "Collecting botocore<1.25.0,>=1.24.26\n",
            "  Downloading botocore-1.24.26-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 32.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.26->boto3->pytorch_transformers) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 17.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.26->boto3->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 33.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.1.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.26 botocore-1.24.26 jmespath-1.0.0 pytorch-transformers-1.2.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxxpKDYJWE8B"
      },
      "outputs": [],
      "source": [
        "# !python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_coul_eff.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_coul_eff.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_bert.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_bert.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_bert.pos "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizerFast\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('PATH-TO-MATBERT/matbert-base-cased', do_lower_case=False)\n",
        "# tokenizer_bert = BertTokenizerFast.from_pretrained('bert-base-cased', do_lower_case=False)"
      ],
      "metadata": {
        "id": "-lo6ZrDDF22u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDE6TID9WE-B"
      },
      "outputs": [],
      "source": [
        "# !python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_bert.pos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhq5i1XKVwYz"
      },
      "outputs": [],
      "source": [
        "# !python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_bert.pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1drwYtQVwbY"
      },
      "outputs": [],
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_modified.py\" 0 1023 train 32 50 0 0 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/coulombic_efficiency.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/coulombic_efficiency.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_bert_ce.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_bert_ce.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_bert_ce.pos "
      ],
      "metadata": {
        "id": "moNhcqXN9Mow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_bert_ce.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_bert_ce.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_bert_ce.pos "
      ],
      "metadata": {
        "id": "v9B24bi29kDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_bert_ce.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_bert_ce.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_bert_ce.pos"
      ],
      "metadata": {
        "id": "KlF_kcoh9oO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ce.py\" 0 1023 train 32 50 0 0 0"
      ],
      "metadata": {
        "id": "UEHQZOaf-L64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer\n",
        "from pytorch_transformers import BertModel"
      ],
      "metadata": {
        "id": "hCGlYLEFte5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SMTH0mm8t90w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Voltage Model"
      ],
      "metadata": {
        "id": "-dJVp0u9g8ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_voltage.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_voltage.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_voltage_bert.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_voltage_bert.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_voltage_bert.pos "
      ],
      "metadata": {
        "id": "9_JnTLFRg_t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_removed_voltage_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_removed_voltage_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_removed_voltage_bert.pos "
      ],
      "metadata": {
        "id": "jv5utcwDg_oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_removed_voltage_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_removed_voltage_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_removed_voltage_bert.pos"
      ],
      "metadata": {
        "id": "tM1WJG8eg_qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_volt2.py\" 0 1023 train 32 50 0 0 0"
      ],
      "metadata": {
        "id": "IsMrdl0rg_l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning Voltage\n"
      ],
      "metadata": {
        "id": "2D_umHo96dpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/voltage.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/voltage.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_voltage_bert.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_voltage_bert.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_voltage_bert.pos "
      ],
      "metadata": {
        "id": "VKbmNYrCg_jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_voltage_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_voltage_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_voltage_bert.pos "
      ],
      "metadata": {
        "id": "vh_cmQnXg_ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_voltage_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_voltage_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_voltage_bert.pos"
      ],
      "metadata": {
        "id": "6bxfkJsQg_Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ft_voltage.py\" 0 1023 train 32 50 0 0 0"
      ],
      "metadata": {
        "id": "7xM9gFBh7K_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training Removing Energy"
      ],
      "metadata": {
        "id": "wntqbeV4z1M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_energy.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_energy.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_energy_bert.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_energy_bert.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_removed_energy_bert.pos "
      ],
      "metadata": {
        "id": "rxXLBwKkz5EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_removed_energy_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_removed_energy_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_removed_energy_bert.pos "
      ],
      "metadata": {
        "id": "7So-rn3M1wIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_removed_energy_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_removed_energy_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_removed_energy_bert.pos"
      ],
      "metadata": {
        "id": "9kiZTQGy2N4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_energy.py\" 0 1023 train 32 50 0 0 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1hU0Mld2geY",
        "outputId": "6db01544-ad04-4564-8e2e-bcac49d46c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "['/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_energy.py', '0', '1023', 'train', '32', '50', '0', '0', '0']\n",
            "100  \t  10  \t  0.5  \t  AspectFirst  \t  Random\n",
            "32  \t  50\n",
            "LSTM\n",
            "loading data......\n",
            "No. of sentences:  3318\n",
            "No. of sentences:  1096\n",
            "Training data size:  3270\n",
            "Development data size:  1096\n",
            "preparing vocabulary......\n",
            "getting pos tags......\n",
            "vocab length:  5035\n",
            "/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/w2v.txt\n",
            "embed dictionary length:  1188\n",
            "Training started......\n",
            "103\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Parameters size:  6555513\n",
            "Seq2SeqModel(\n",
            "  (encoder): Encoder(\n",
            "    (bert_vec): BERT(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (pos_embeddings): POSEmbeddings(\n",
            "      (embeddings): Embedding(44, 25, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (lstm): LSTM(793, 150, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (w): Linear(in_features=1200, out_features=300, bias=True)\n",
            "    (attention1): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (attention2): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (lstm): LSTMCell(1800, 300)\n",
            "    (ap_first_pointer_lstm): LSTM(600, 150, batch_first=True, bidirectional=True)\n",
            "    (op_second_pointer_lstm): LSTM(900, 150, batch_first=True, bidirectional=True)\n",
            "    (ap_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (ap_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (sent_lin): Linear(in_features=1500, out_features=7, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "weight factor:  1.0\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "Epoch:  1\n",
            "100% 103/103 [01:10<00:00,  1.47it/s]\n",
            "Training loss:  4.131165833149142\n",
            "Training time:  0:01:10.140172\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.661285\n",
            "1877\n",
            "1124  \t  1246  \t  953\n",
            "P:  0.848\n",
            "R:  0.765\n",
            "F1:  0.8042194042891633\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "100% 103/103 [01:11<00:00,  1.43it/s]\n",
            "Training loss:  2.0841694155943045\n",
            "Training time:  0:01:11.975533\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.858194\n",
            "1727\n",
            "1125  \t  1246  \t  970\n",
            "P:  0.862\n",
            "R:  0.778\n",
            "F1:  0.8182201552760486\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "100% 103/103 [01:11<00:00,  1.43it/s]\n",
            "Training loss:  1.8393647427697783\n",
            "Training time:  0:01:11.848450\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.830325\n",
            "2057\n",
            "1123  \t  1246  \t  986\n",
            "P:  0.878\n",
            "R:  0.791\n",
            "F1:  0.8324187370917194\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  1.7490763947801682\n",
            "Training time:  0:01:10.772458\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.819992\n",
            "3453\n",
            "1130  \t  1246  \t  1004\n",
            "P:  0.888\n",
            "R:  0.806\n",
            "F1:  0.8451178401226491\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  1.6314135153316758\n",
            "Training time:  0:01:10.813963\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.801039\n",
            "1805\n",
            "1123  \t  1246  \t  1004\n",
            "P:  0.894\n",
            "R:  0.806\n",
            "F1:  0.8476150224440605\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "100% 103/103 [01:11<00:00,  1.43it/s]\n",
            "Training loss:  1.5493458087004504\n",
            "Training time:  0:01:11.913131\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.853787\n",
            "2499\n",
            "1126  \t  1246  \t  997\n",
            "P:  0.885\n",
            "R:  0.8\n",
            "F1:  0.8406408044492166\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  1.5100565199713105\n",
            "Training time:  0:01:10.865058\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.823506\n",
            "2045\n",
            "1130  \t  1246  \t  991\n",
            "P:  0.877\n",
            "R:  0.795\n",
            "F1:  0.8341750791799803\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "100% 103/103 [01:09<00:00,  1.47it/s]\n",
            "Training loss:  1.463239397817445\n",
            "Training time:  0:01:09.947718\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.816730\n",
            "2380\n",
            "1121  \t  1246  \t  999\n",
            "P:  0.891\n",
            "R:  0.802\n",
            "F1:  0.844106458885139\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  9\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  1.4151305776197933\n",
            "Training time:  0:01:10.780842\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.777581\n",
            "1937\n",
            "1113  \t  1246  \t  1004\n",
            "P:  0.902\n",
            "R:  0.806\n",
            "F1:  0.8512081340506439\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  10\n",
            "100% 103/103 [01:11<00:00,  1.43it/s]\n",
            "Training loss:  1.3607334917031446\n",
            "Training time:  0:01:11.989372\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.816399\n",
            "2061\n",
            "1137  \t  1246  \t  1018\n",
            "P:  0.895\n",
            "R:  0.817\n",
            "F1:  0.8543852237066056\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  11\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  1.316575099542303\n",
            "Training time:  0:01:11.568615\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.810374\n",
            "2162\n",
            "1157  \t  1246  \t  1019\n",
            "P:  0.881\n",
            "R:  0.818\n",
            "F1:  0.8481065284995921\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  12\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  1.298559005978038\n",
            "Training time:  0:01:10.357853\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.903141\n",
            "2120\n",
            "1137  \t  1246  \t  1011\n",
            "P:  0.889\n",
            "R:  0.811\n",
            "F1:  0.8485102761615437\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  13\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  1.2621671736819073\n",
            "Training time:  0:01:11.275208\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.817485\n",
            "1998\n",
            "1156  \t  1246  \t  1030\n",
            "P:  0.891\n",
            "R:  0.827\n",
            "F1:  0.8576186461239422\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  14\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  1.2039848357728384\n",
            "Training time:  0:01:10.910767\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.860180\n",
            "2148\n",
            "1130  \t  1246  \t  1015\n",
            "P:  0.898\n",
            "R:  0.815\n",
            "F1:  0.8543770993818305\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  15\n",
            "100% 103/103 [01:10<00:00,  1.47it/s]\n",
            "Training loss:  1.2040585175301264\n",
            "Training time:  0:01:10.227643\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.780529\n",
            "2067\n",
            "1158  \t  1246  \t  1023\n",
            "P:  0.883\n",
            "R:  0.821\n",
            "F1:  0.8510815257816494\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  16\n",
            "100% 103/103 [01:09<00:00,  1.48it/s]\n",
            "Training loss:  1.1715004362382935\n",
            "Training time:  0:01:09.703173\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.775559\n",
            "1681\n",
            "1144  \t  1246  \t  1025\n",
            "P:  0.896\n",
            "R:  0.823\n",
            "F1:  0.8577405807759879\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  17\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  1.134834868236653\n",
            "Training time:  0:01:11.094932\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.810143\n",
            "1839\n",
            "1164  \t  1246  \t  1031\n",
            "P:  0.886\n",
            "R:  0.827\n",
            "F1:  0.8556016547497255\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  18\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  1.070026380344502\n",
            "Training time:  0:01:10.343608\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.809410\n",
            "1533\n",
            "1168  \t  1246  \t  1038\n",
            "P:  0.889\n",
            "R:  0.833\n",
            "F1:  0.8599834249898102\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  19\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  1.0665971332962074\n",
            "Training time:  0:01:11.280094\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.747838\n",
            "1683\n",
            "1185  \t  1246  \t  1032\n",
            "P:  0.871\n",
            "R:  0.828\n",
            "F1:  0.8490333146177182\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  20\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  1.033108340015689\n",
            "Training time:  0:01:11.291132\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.655068\n",
            "1588\n",
            "1182  \t  1246  \t  1042\n",
            "P:  0.882\n",
            "R:  0.836\n",
            "F1:  0.8583195996092541\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  21\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  0.9993438888522028\n",
            "Training time:  0:01:11.141263\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.820172\n",
            "1750\n",
            "1210  \t  1246  \t  1063\n",
            "P:  0.879\n",
            "R:  0.853\n",
            "F1:  0.8656351741471197\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  22\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.9841948012703831\n",
            "Training time:  0:01:11.585504\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.744993\n",
            "1704\n",
            "1218  \t  1246  \t  1070\n",
            "P:  0.878\n",
            "R:  0.859\n",
            "F1:  0.8685064885000897\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  23\n",
            "100% 103/103 [01:10<00:00,  1.47it/s]\n",
            "Training loss:  0.9608013363717829\n",
            "Training time:  0:01:10.054806\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.807018\n",
            "1731\n",
            "1191  \t  1246  \t  1056\n",
            "P:  0.887\n",
            "R:  0.848\n",
            "F1:  0.8666393056232556\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  24\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.906468341940815\n",
            "Training time:  0:01:11.474698\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.721061\n",
            "1974\n",
            "1234  \t  1246  \t  1083\n",
            "P:  0.878\n",
            "R:  0.869\n",
            "F1:  0.8733870917672673\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  25\n",
            "100% 103/103 [01:09<00:00,  1.49it/s]\n",
            "Training loss:  0.8785452101994486\n",
            "Training time:  0:01:09.212215\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.779160\n",
            "1888\n",
            "1229  \t  1246  \t  1085\n",
            "P:  0.883\n",
            "R:  0.871\n",
            "F1:  0.8767676717608279\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  26\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  0.8871273114843276\n",
            "Training time:  0:01:11.114737\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.812391\n",
            "1767\n",
            "1226  \t  1246  \t  1086\n",
            "P:  0.886\n",
            "R:  0.872\n",
            "F1:  0.8786407716922479\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  27\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  0.8378952706901772\n",
            "Training time:  0:01:11.274016\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.766250\n",
            "1676\n",
            "1206  \t  1246  \t  1065\n",
            "P:  0.883\n",
            "R:  0.855\n",
            "F1:  0.8686786246842944\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  28\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.8019637126945754\n",
            "Training time:  0:01:10.641731\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.776268\n",
            "1627\n",
            "1203  \t  1246  \t  1067\n",
            "P:  0.887\n",
            "R:  0.856\n",
            "F1:  0.8713760668604932\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  29\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.8036767974929903\n",
            "Training time:  0:01:10.677684\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.814870\n",
            "1869\n",
            "1245  \t  1246  \t  1089\n",
            "P:  0.875\n",
            "R:  0.874\n",
            "F1:  0.8743476465385449\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  30\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.8155217205436485\n",
            "Training time:  0:01:10.418175\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.823066\n",
            "1701\n",
            "1216  \t  1246  \t  1088\n",
            "P:  0.895\n",
            "R:  0.873\n",
            "F1:  0.8838342760658616\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  31\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.7590524345925711\n",
            "Training time:  0:01:11.564397\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.780525\n",
            "1713\n",
            "1196  \t  1246  \t  1059\n",
            "P:  0.885\n",
            "R:  0.85\n",
            "F1:  0.8673218623168603\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  32\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.7342434823513031\n",
            "Training time:  0:01:10.700276\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.863999\n",
            "1725\n",
            "1215  \t  1246  \t  1078\n",
            "P:  0.887\n",
            "R:  0.865\n",
            "F1:  0.8760666345710815\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  33\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.7344582102541785\n",
            "Training time:  0:01:11.608619\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.756228\n",
            "1649\n",
            "1204  \t  1246  \t  1066\n",
            "P:  0.885\n",
            "R:  0.856\n",
            "F1:  0.8702040766270189\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  34\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  0.6997238912628693\n",
            "Training time:  0:01:10.838342\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.850067\n",
            "1670\n",
            "1231  \t  1246  \t  1087\n",
            "P:  0.883\n",
            "R:  0.872\n",
            "F1:  0.8776746013717809\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  35\n",
            "100% 103/103 [01:09<00:00,  1.48it/s]\n",
            "Training loss:  0.6984497467869694\n",
            "Training time:  0:01:09.692075\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.843645\n",
            "1747\n",
            "1228  \t  1246  \t  1093\n",
            "P:  0.89\n",
            "R:  0.877\n",
            "F1:  0.8835893240149488\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  36\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.6700775509031074\n",
            "Training time:  0:01:11.601664\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.761182\n",
            "1655\n",
            "1233  \t  1246  \t  1088\n",
            "P:  0.882\n",
            "R:  0.873\n",
            "F1:  0.8777732906767994\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  37\n",
            "100% 103/103 [01:09<00:00,  1.48it/s]\n",
            "Training loss:  0.6310148142205859\n",
            "Training time:  0:01:09.444981\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.766746\n",
            "1646\n",
            "1226  \t  1246  \t  1082\n",
            "P:  0.883\n",
            "R:  0.868\n",
            "F1:  0.8754045257375815\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  38\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.6391853491947489\n",
            "Training time:  0:01:10.443978\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.741566\n",
            "1673\n",
            "1225  \t  1246  \t  1088\n",
            "P:  0.888\n",
            "R:  0.873\n",
            "F1:  0.8806151305658764\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  39\n",
            "100% 103/103 [01:11<00:00,  1.45it/s]\n",
            "Training loss:  0.6305916273188823\n",
            "Training time:  0:01:11.177897\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.819645\n",
            "1729\n",
            "1249  \t  1246  \t  1101\n",
            "P:  0.882\n",
            "R:  0.884\n",
            "F1:  0.8825651252534538\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  40\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  0.6296799631373396\n",
            "Training time:  0:01:10.895502\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.763137\n",
            "1766\n",
            "1245  \t  1246  \t  1098\n",
            "P:  0.882\n",
            "R:  0.881\n",
            "F1:  0.8815736601876237\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  41\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.5873881045692754\n",
            "Training time:  0:01:10.552348\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.766832\n",
            "1585\n",
            "1211  \t  1246  \t  1083\n",
            "P:  0.894\n",
            "R:  0.869\n",
            "F1:  0.8815628765567203\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  42\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.5904089507547398\n",
            "Training time:  0:01:11.382192\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.818602\n",
            "1734\n",
            "1238  \t  1246  \t  1089\n",
            "P:  0.88\n",
            "R:  0.874\n",
            "F1:  0.8768115891958909\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  43\n",
            "100% 103/103 [01:10<00:00,  1.47it/s]\n",
            "Training loss:  0.5907261008487165\n",
            "Training time:  0:01:10.282797\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.787852\n",
            "1594\n",
            "1206  \t  1246  \t  1074\n",
            "P:  0.891\n",
            "R:  0.862\n",
            "F1:  0.8760195708506292\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  44\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.6008111804145054\n",
            "Training time:  0:01:10.527052\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.794718\n",
            "1755\n",
            "1234  \t  1246  \t  1087\n",
            "P:  0.881\n",
            "R:  0.872\n",
            "F1:  0.8766128982188541\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  45\n",
            "100% 103/103 [01:11<00:00,  1.44it/s]\n",
            "Training loss:  0.572683736175588\n",
            "Training time:  0:01:11.289031\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.862361\n",
            "1627\n",
            "1214  \t  1246  \t  1082\n",
            "P:  0.891\n",
            "R:  0.868\n",
            "F1:  0.8796747917416619\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  46\n",
            "100% 103/103 [01:10<00:00,  1.46it/s]\n",
            "Training loss:  0.5615439277540133\n",
            "Training time:  0:01:10.749215\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.882407\n",
            "1605\n",
            "1224  \t  1246  \t  1087\n",
            "P:  0.888\n",
            "R:  0.872\n",
            "F1:  0.880161938313108\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  47\n",
            "100% 103/103 [01:09<00:00,  1.47it/s]\n",
            "Training loss:  0.5770794352860127\n",
            "Training time:  0:01:09.862483\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.834999\n",
            "1650\n",
            "1239  \t  1246  \t  1087\n",
            "P:  0.877\n",
            "R:  0.872\n",
            "F1:  0.8748490895604032\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  48\n",
            "100% 103/103 [01:11<00:00,  1.43it/s]\n",
            "Training loss:  0.5286814997207772\n",
            "Training time:  0:01:11.785147\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.892560\n",
            "1690\n",
            "1222  \t  1246  \t  1088\n",
            "P:  0.89\n",
            "R:  0.873\n",
            "F1:  0.8816855703579957\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  49\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  0.5048364161794047\n",
            "Training time:  0:01:10.994053\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.777255\n",
            "1661\n",
            "1241  \t  1246  \t  1086\n",
            "P:  0.875\n",
            "R:  0.872\n",
            "F1:  0.8733413701437812\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  50\n",
            "100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "Training loss:  0.5215667913694984\n",
            "Training time:  0:01:10.943706\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.742232\n",
            "1700\n",
            "1238  \t  1246  \t  1094\n",
            "P:  0.884\n",
            "R:  0.878\n",
            "F1:  0.8808373540911886\n",
            "\n",
            "\n",
            "\n",
            "*******\n",
            "Best Epoch:  30\n",
            "Best Epoch Seed:  1053\n",
            "Best Dev F1:  0.884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hnw8n0Cx_ndI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Fine Tuning Energy"
      ],
      "metadata": {
        "id": "GtiDrx42KNBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/energy.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/energy.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_energy_bert.sent /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_energy_bert.pointer /content/drive/MyDrive/\"Research Internship - IIT Kgp\"/New_Dataset_Fine_Tune/train_energy_bert.pos "
      ],
      "metadata": {
        "id": "tYpo2BrTKUNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_energy_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_energy_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/test_energy_bert.pos "
      ],
      "metadata": {
        "id": "bbyKqmNrKT5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/helper.py\" /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_energy_bert.sent /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_energy_bert.pointer /content/drive/MyDrive/'Research Internship - IIT Kgp'/New_Dataset_Fine_Tune/dev_energy_bert.pos"
      ],
      "metadata": {
        "id": "nG0fliXMKTqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ft_energy.py\" 0 1023 train 32 50 0 0 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cpnMeNlKRi-",
        "outputId": "39b12a9e-a792-4749-e8b9-8f8e7a0977f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "['/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ft_energy.py', '0', '1023', 'train', '32', '50', '0', '0', '0']\n",
            "100  \t  10  \t  0.5  \t  AspectFirst  \t  Random\n",
            "32  \t  50\n",
            "LSTM\n",
            "loading data......\n",
            "No. of sentences:  109\n",
            "No. of sentences:  1096\n",
            "Training data size:  109\n",
            "Development data size:  1096\n",
            "preparing vocabulary......\n",
            "getting pos tags......\n",
            "vocab length:  3199\n",
            "/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/w2v.txt\n",
            "embed dictionary length:  554\n",
            "Training started......\n",
            "4\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Parameters size:  6555513\n",
            "Seq2SeqModel(\n",
            "  (encoder): Encoder(\n",
            "    (bert_vec): BERT(\n",
            "      (bert): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (pos_embeddings): POSEmbeddings(\n",
            "      (embeddings): Embedding(44, 25, padding_idx=0)\n",
            "      (dropout): Dropout(p=0.5, inplace=False)\n",
            "    )\n",
            "    (lstm): LSTM(793, 150, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (w): Linear(in_features=1200, out_features=300, bias=True)\n",
            "    (attention1): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (attention2): Attention(\n",
            "      (linear_ctx): Linear(in_features=300, out_features=300, bias=False)\n",
            "      (linear_query): Linear(in_features=300, out_features=300, bias=True)\n",
            "      (v): Linear(in_features=300, out_features=1, bias=True)\n",
            "    )\n",
            "    (lstm): LSTMCell(1800, 300)\n",
            "    (ap_first_pointer_lstm): LSTM(600, 150, batch_first=True, bidirectional=True)\n",
            "    (op_second_pointer_lstm): LSTM(900, 150, batch_first=True, bidirectional=True)\n",
            "    (ap_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (ap_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_start_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (op_end_lin): Linear(in_features=300, out_features=1, bias=True)\n",
            "    (sent_lin): Linear(in_features=1500, out_features=7, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "weight factor:  1.0\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 1e-05\n",
            ")\n",
            "Epoch:  1\n",
            "100% 4/4 [00:02<00:00,  1.57it/s]\n",
            "Training loss:  11.572067499160767\n",
            "Training time:  0:00:02.542872\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.16it/s]\n",
            "Prediction time:  0:00:30.182460\n",
            "2001\n",
            "1204  \t  1246  \t  1033\n",
            "P:  0.858\n",
            "R:  0.829\n",
            "F1:  0.8432653011170347\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  2\n",
            "100% 4/4 [00:02<00:00,  1.55it/s]\n",
            "Training loss:  5.552412152290344\n",
            "Training time:  0:00:02.584318\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.693339\n",
            "2381\n",
            "1189  \t  1246  \t  1036\n",
            "P:  0.871\n",
            "R:  0.831\n",
            "F1:  0.8509240196364078\n",
            "model saved......\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  3\n",
            "100% 4/4 [00:02<00:00,  1.51it/s]\n",
            "Training loss:  3.397372305393219\n",
            "Training time:  0:00:02.653086\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.940937\n",
            "1875\n",
            "1161  \t  1246  \t  881\n",
            "P:  0.759\n",
            "R:  0.707\n",
            "F1:  0.7320315695743115\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  4\n",
            "100% 4/4 [00:02<00:00,  1.55it/s]\n",
            "Training loss:  2.6125577688217163\n",
            "Training time:  0:00:02.574815\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.904709\n",
            "1410\n",
            "1160  \t  1246  \t  414\n",
            "P:  0.357\n",
            "R:  0.332\n",
            "F1:  0.3441396458763455\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  5\n",
            "100% 4/4 [00:02<00:00,  1.66it/s]\n",
            "Training loss:  2.192112445831299\n",
            "Training time:  0:00:02.406208\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.890162\n",
            "1411\n",
            "1179  \t  1246  \t  258\n",
            "P:  0.219\n",
            "R:  0.207\n",
            "F1:  0.21278350015670117\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  6\n",
            "100% 4/4 [00:02<00:00,  1.59it/s]\n",
            "Training loss:  1.695033997297287\n",
            "Training time:  0:00:02.522858\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.14it/s]\n",
            "Prediction time:  0:00:30.819267\n",
            "1679\n",
            "1277  \t  1246  \t  359\n",
            "P:  0.281\n",
            "R:  0.288\n",
            "F1:  0.28458184200602976\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  7\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "Training loss:  1.6878464818000793\n",
            "Training time:  0:00:02.397146\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.845642\n",
            "1785\n",
            "1305  \t  1246  \t  371\n",
            "P:  0.284\n",
            "R:  0.298\n",
            "F1:  0.2908663219310097\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  8\n",
            "100% 4/4 [00:02<00:00,  1.59it/s]\n",
            "Training loss:  1.4781957268714905\n",
            "Training time:  0:00:02.508559\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.856244\n",
            "1804\n",
            "1311  \t  1246  \t  342\n",
            "P:  0.261\n",
            "R:  0.274\n",
            "F1:  0.26750097270939066\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  9\n",
            "100% 4/4 [00:02<00:00,  1.56it/s]\n",
            "Training loss:  1.3095933198928833\n",
            "Training time:  0:00:02.561692\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.906480\n",
            "1705\n",
            "1293  \t  1246  \t  329\n",
            "P:  0.254\n",
            "R:  0.264\n",
            "F1:  0.25915714348332697\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  10\n",
            "100% 4/4 [00:02<00:00,  1.67it/s]\n",
            "Training loss:  1.23075470328331\n",
            "Training time:  0:00:02.396590\n",
            "\n",
            "Dev Results\n",
            "\n",
            "100% 35/35 [00:30<00:00,  1.13it/s]\n",
            "Prediction time:  0:00:30.884840\n",
            "1795\n",
            "1300  \t  1246  \t  380\n",
            "P:  0.292\n",
            "R:  0.305\n",
            "F1:  0.2985074576864716\n",
            "\n",
            "\n",
            "\n",
            "Epoch:  11\n",
            "100% 4/4 [00:02<00:00,  1.60it/s]\n",
            "Training loss:  1.2757213115692139\n",
            "Training time:  0:00:02.503767\n",
            "\n",
            "Dev Results\n",
            "\n",
            " 37% 13/35 [00:10<00:17,  1.28it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ft_energy.py\", line 1469, in <module>\n",
            "    train_model(model_name, train_data, dev_data, model_file_name)\n",
            "  File \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ft_energy.py\", line 1288, in train_model\n",
            "    dev_preds = predict(dev_samples, model, model_id)\n",
            "  File \"/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert_ptrnet_decoder_ft_energy.py\", line 1107, in predict\n",
            "    rel += list(outputs[0].data.cpu().numpy())\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###AfterWorks"
      ],
      "metadata": {
        "id": "uBG3eUgy95W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/My Drive/New_dataset/bert_ptrnet_decoder.py\" 0 1023 test 32 50 0 0 0"
      ],
      "metadata": {
        "id": "fV7O79Ka6FTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "LyreXFBk7ZTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_model_name = '/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/matbert-base-cased'\n",
        "# bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=False)"
      ],
      "metadata": {
        "id": "I4n916d17ZdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = '/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/MatBERT_output'\n",
        "#, do_lower_case=False)"
      ],
      "metadata": {
        "id": "gf7uoRKIl6VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_transformers import BERT_CLASS"
      ],
      "metadata": {
        "id": "kY35E65DCjhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wpcMntxrC-8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertModel"
      ],
      "metadata": {
        "id": "y_pJD4UvB1G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = torch.load(bert_model_name)"
      ],
      "metadata": {
        "id": "26qtx617Ohr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_2 = BertModel.from_pretrained(bert_model_name, cache_dir=None, from_tf=False, state_dict=None)#, *input, **kwargs)"
      ],
      "metadata": {
        "id": "3WaE3r5HOw3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "Va8PCJfSDWKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_2 = model = BertTokenizer.from_pretrained(bert_model_name, cache_dir=None, from_tf=False, state_dict=None)#, *input, **kwargs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87OB4f7tBvmQ",
        "outputId": "266af791-742f-400d-b7bd-a9b7538750af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model name '/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/MatBERT_output' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed '/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/MatBERT_output' was a path or url but couldn't find tokenizer filesat this path or url.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/MatBERT_output/vocab.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "oG4uf1dyDEsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./vocab.txt','a+') as f:\n",
        "  f.write(str(data))"
      ],
      "metadata": {
        "id": "QsTxzd9fK26T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"...\")"
      ],
      "metadata": {
        "id": "Ln6GGlxCK352"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/MyDrive/Research Internship - IIT Kgp/New_Dataset_Fine_Tune/MatBERT_output/model.h5py')"
      ],
      "metadata": {
        "id": "7oYLFQewp_8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CCE0dywwq-NZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of BERT_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}